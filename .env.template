# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Alternative: Use Ollama for local LLM
# If using Ollama, you can leave OPENAI_API_KEY empty
# Make sure Ollama is running: ollama serve
# And the model is available: ollama pull qwen3:1.7b
OLLAMA_BASE_URL=http://localhost:11434

# Workshop Configuration
WORKSHOP_LOG_LEVEL=INFO
MCP_SERVER_HOST=localhost
MCP_SERVER_PORT=8000